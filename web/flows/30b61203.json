{
  "id": "30b61203",
  "name": "xxx",
  "description": "",
  "nodes": [
    {
      "id": "node-1",
      "type": "on_flow_start",
      "position": {
        "x": -176.0,
        "y": 48.0
      },
      "data": {
        "nodeType": "on_flow_start",
        "label": "On Flow Start",
        "icon": "&#x1F3C1;",
        "headerColor": "#C0392B",
        "inputs": [],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          }
        ]
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-4",
      "type": "llm_call",
      "position": {
        "x": 176.0,
        "y": 48.0
      },
      "data": {
        "nodeType": "llm_call",
        "label": "LLM Call",
        "icon": "&#x1F4AD;",
        "headerColor": "#3498DB",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "include_context",
            "label": "use_context",
            "type": "boolean",
            "description": "When true, include this run's active context messages (context.messages) in the LLM request. If the pin is not connected, the node checkbox is used. Default: false."
          },
          {
            "id": "provider",
            "label": "provider",
            "type": "provider",
            "description": "LLM provider id (e.g. LMStudio). If unset, uses the node’s configured provider."
          },
          {
            "id": "model",
            "label": "model",
            "type": "model",
            "description": "LLM model id/name. If unset, uses the node’s configured model."
          },
          {
            "id": "system",
            "label": "system",
            "type": "string",
            "description": "Optional system prompt for this single call."
          },
          {
            "id": "prompt",
            "label": "prompt",
            "type": "string",
            "description": "User prompt/content for this single call."
          },
          {
            "id": "tools",
            "label": "tools",
            "type": "array",
            "description": "Allowlist of tools exposed to the model as ToolSpecs (model may request tool calls; execution is done via a Tool Calls node)."
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "response",
            "label": "response",
            "type": "string",
            "description": "Assistant text content (best-effort). For tool calls, content may be empty."
          },
          {
            "id": "result",
            "label": "result",
            "type": "object",
            "description": "Full normalized LLM result (content, tool_calls, usage, provider/model metadata, trace_id)."
          }
        ],
        "pinDefaults": {
          "system": "Resolve the provided query ",
          "prompt": "i am laurent-philippe albou, a research scientist",
          "include_context": false
        },
        "effectConfig": {
          "provider": "lmstudio",
          "model": "qwen/qwen3-next-80b"
        }
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-9",
      "type": "memory_note",
      "position": {
        "x": 544.0,
        "y": 48.0
      },
      "data": {
        "nodeType": "memory_note",
        "label": "Memorize",
        "icon": "&#x1F4DD;",
        "headerColor": "#2ECC71",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "keep_in_context",
            "label": "in_context",
            "type": "boolean",
            "description": "When true, also insert the stored note into this run's context.messages (synthetic system message). If the pin is not connected, the node checkbox is used. Default: false."
          },
          {
            "id": "scope",
            "label": "scope",
            "type": "string",
            "description": "Where to store/index the note: run (this run), session (root run of this run-tree), or global (shared global memory run)."
          },
          {
            "id": "content",
            "label": "content",
            "type": "string",
            "description": "The note text to store durably (keep it short; prefer references in sources for large payloads)."
          },
          {
            "id": "location",
            "label": "location",
            "type": "string",
            "description": "Optional location label (where the note was produced, e.g. \"flow:my_flow/node-12\"). Useful for filtering."
          },
          {
            "id": "tags",
            "label": "tags",
            "type": "object",
            "description": "Key/value tags for filtering (e.g. {topic:\"memory\", person:\"laurent\"}). Values must be strings."
          },
          {
            "id": "sources",
            "label": "sources",
            "type": "object",
            "description": "Optional provenance refs (e.g. {run_id, span_ids, message_ids}). The note stores refs, not the full source content."
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "note_id",
            "label": "note_id",
            "type": "string",
            "description": "The stored note’s span_id / artifact_id. Use it for Recall into context (span_ids) or for precise Recall."
          }
        ],
        "effectConfig": {},
        "pinDefaults": {
          "keep_in_context": true
        }
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-10",
      "type": "llm_call",
      "position": {
        "x": 880.0,
        "y": 48.0
      },
      "data": {
        "nodeType": "llm_call",
        "label": "LLM Call",
        "icon": "&#x1F4AD;",
        "headerColor": "#3498DB",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "include_context",
            "label": "use_context",
            "type": "boolean",
            "description": "When true, include this run's active context messages (context.messages) in the LLM request. If the pin is not connected, the node checkbox is used. Default: false."
          },
          {
            "id": "provider",
            "label": "provider",
            "type": "provider",
            "description": "LLM provider id (e.g. LMStudio). If unset, uses the node’s configured provider."
          },
          {
            "id": "model",
            "label": "model",
            "type": "model",
            "description": "LLM model id/name. If unset, uses the node’s configured model."
          },
          {
            "id": "system",
            "label": "system",
            "type": "string",
            "description": "Optional system prompt for this single call."
          },
          {
            "id": "prompt",
            "label": "prompt",
            "type": "string",
            "description": "User prompt/content for this single call."
          },
          {
            "id": "tools",
            "label": "tools",
            "type": "array",
            "description": "Allowlist of tools exposed to the model as ToolSpecs (model may request tool calls; execution is done via a Tool Calls node)."
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "response",
            "label": "response",
            "type": "string",
            "description": "Assistant text content (best-effort). For tool calls, content may be empty."
          },
          {
            "id": "result",
            "label": "result",
            "type": "object",
            "description": "Full normalized LLM result (content, tool_calls, usage, provider/model metadata, trace_id)."
          }
        ],
        "effectConfig": {
          "provider": "lmstudio",
          "model": "zai-org/glm-4.6v-flash"
        },
        "pinDefaults": {
          "prompt": "who am i ?",
          "include_context": true
        }
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-11",
      "type": "literal_string",
      "position": {
        "x": -32.0,
        "y": 336.0
      },
      "data": {
        "nodeType": "literal_string",
        "label": "information",
        "icon": "\"",
        "headerColor": "#FF00FF",
        "inputs": [],
        "outputs": [
          {
            "id": "value",
            "label": "value",
            "type": "string"
          }
        ],
        "literalValue": "i am laurent-philippe albou, a research scientist"
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    }
  ],
  "edges": [
    {
      "id": "edge-1767472260757",
      "source": "node-1",
      "sourceHandle": "exec-out",
      "target": "node-4",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1767472299633",
      "source": "node-4",
      "sourceHandle": "exec-out",
      "target": "node-9",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1767472329167",
      "source": "node-9",
      "sourceHandle": "exec-out",
      "target": "node-10",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1767473778511",
      "source": "node-11",
      "sourceHandle": "value",
      "target": "node-9",
      "targetHandle": "content",
      "animated": false
    },
    {
      "id": "edge-1767473789808",
      "source": "node-11",
      "sourceHandle": "value",
      "target": "node-4",
      "targetHandle": "prompt",
      "animated": false
    }
  ],
  "entryNode": "node-1",
  "created_at": "2026-01-03T19:08:23.886538",
  "updated_at": "2026-01-04T00:50:49.772390"
}