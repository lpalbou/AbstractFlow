{
  "id": "a562669c",
  "name": "answer-with-review",
  "description": "",
  "interfaces": [],
  "nodes": [
    {
      "id": "node-1",
      "type": "llm_call",
      "position": {
        "x": 496.0,
        "y": -288.0
      },
      "data": {
        "nodeType": "llm_call",
        "label": "LLM Call",
        "icon": "&#x1F4AD;",
        "headerColor": "#3498DB",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "include_context",
            "label": "use_context",
            "type": "boolean",
            "description": "When true, include this run's active context messages (context.messages) in the LLM request. If the pin is not connected, the node checkbox is used. Default: false."
          },
          {
            "id": "provider",
            "label": "provider",
            "type": "provider",
            "description": "LLM provider id (e.g. LMStudio). If unset, uses the node’s configured provider."
          },
          {
            "id": "model",
            "label": "model",
            "type": "model",
            "description": "LLM model id/name. If unset, uses the node’s configured model."
          },
          {
            "id": "system",
            "label": "system",
            "type": "string",
            "description": "Optional system prompt for this single call."
          },
          {
            "id": "prompt",
            "label": "prompt",
            "type": "string",
            "description": "User prompt/content for this single call."
          },
          {
            "id": "tools",
            "label": "tools",
            "type": "tools",
            "description": "Allowlist of tools exposed to the model as ToolSpecs (model may request tool calls; execution is done via a Tool Calls node)."
          },
          {
            "id": "response_schema",
            "label": "structured_output",
            "type": "object",
            "description": "Optional JSON Schema object (type=object) the assistant content must conform to."
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "response",
            "label": "response",
            "type": "string",
            "description": "Assistant text content (best-effort). For tool calls, content may be empty."
          }
        ],
        "effectConfig": {
          "provider": "lmstudio",
          "model": "qwen/qwen3-next-80b"
        },
        "pinDefaults": {}
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-2",
      "type": "on_flow_start",
      "position": {
        "x": 256.0,
        "y": -288.0
      },
      "data": {
        "nodeType": "on_flow_start",
        "label": "On Flow Start",
        "icon": "&#x1F3C1;",
        "headerColor": "#C0392B",
        "inputs": [],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "query",
            "label": "query",
            "type": "string"
          }
        ]
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-4",
      "type": "llm_call",
      "position": {
        "x": 1008.0,
        "y": -160.0
      },
      "data": {
        "nodeType": "llm_call",
        "label": "LLM Call",
        "icon": "&#x1F4AD;",
        "headerColor": "#3498DB",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "include_context",
            "label": "use_context",
            "type": "boolean",
            "description": "When true, include this run's active context messages (context.messages) in the LLM request. If the pin is not connected, the node checkbox is used. Default: false."
          },
          {
            "id": "provider",
            "label": "provider",
            "type": "provider",
            "description": "LLM provider id (e.g. LMStudio). If unset, uses the node’s configured provider."
          },
          {
            "id": "model",
            "label": "model",
            "type": "model",
            "description": "LLM model id/name. If unset, uses the node’s configured model."
          },
          {
            "id": "system",
            "label": "system",
            "type": "string",
            "description": "Optional system prompt for this single call."
          },
          {
            "id": "prompt",
            "label": "prompt",
            "type": "string",
            "description": "User prompt/content for this single call."
          },
          {
            "id": "tools",
            "label": "tools",
            "type": "tools",
            "description": "Allowlist of tools exposed to the model as ToolSpecs (model may request tool calls; execution is done via a Tool Calls node)."
          },
          {
            "id": "response_schema",
            "label": "structured_output",
            "type": "object",
            "description": "Optional JSON Schema object (type=object) the assistant content must conform to."
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "response",
            "label": "response",
            "type": "string",
            "description": "Assistant text content (best-effort). For tool calls, content may be empty."
          }
        ],
        "effectConfig": {
          "provider": "lmstudio",
          "model": "qwen/qwen3-next-80b"
        },
        "pinDefaults": {}
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-5",
      "type": "concat",
      "position": {
        "x": 720.0,
        "y": -48.0
      },
      "data": {
        "nodeType": "concat",
        "label": "Concat",
        "icon": "&#x2795;",
        "headerColor": "#E74C3C",
        "inputs": [
          {
            "id": "a",
            "label": "a",
            "type": "string"
          },
          {
            "id": "b",
            "label": "b",
            "type": "string"
          }
        ],
        "outputs": [
          {
            "id": "result",
            "label": "result",
            "type": "string"
          }
        ],
        "concatConfig": {
          "separator": " "
        }
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-6",
      "type": "literal_string",
      "position": {
        "x": 720.0,
        "y": -144.0
      },
      "data": {
        "nodeType": "literal_string",
        "label": "String",
        "icon": "\"",
        "headerColor": "#FF00FF",
        "inputs": [],
        "outputs": [
          {
            "id": "value",
            "label": "value",
            "type": "string"
          }
        ],
        "literalValue": "Please do a critical review of the answer below and look especially for possible mistakes, misinterpretations or inconsistencies. Note them, then provide a final answer\n"
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-7",
      "type": "answer_user",
      "position": {
        "x": 1312.0,
        "y": -160.0
      },
      "data": {
        "nodeType": "answer_user",
        "label": "Answer User",
        "icon": "&#x1F4AC;",
        "headerColor": "#9B59B6",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "message",
            "label": "message",
            "type": "string"
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "message",
            "label": "message",
            "type": "string"
          }
        ]
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    }
  ],
  "edges": [
    {
      "id": "edge-1766469544212",
      "source": "node-2",
      "sourceHandle": "exec-out",
      "target": "node-1",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1766469553082",
      "source": "node-2",
      "sourceHandle": "query",
      "target": "node-1",
      "targetHandle": "prompt",
      "animated": false
    },
    {
      "id": "edge-1766469596093",
      "source": "node-1",
      "sourceHandle": "exec-out",
      "target": "node-4",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1766469623377",
      "source": "node-6",
      "sourceHandle": "value",
      "target": "node-5",
      "targetHandle": "a",
      "animated": false
    },
    {
      "id": "edge-1766469626191",
      "source": "node-1",
      "sourceHandle": "response",
      "target": "node-5",
      "targetHandle": "b",
      "animated": false
    },
    {
      "id": "edge-1766469628110",
      "source": "node-5",
      "sourceHandle": "result",
      "target": "node-4",
      "targetHandle": "prompt",
      "animated": false
    },
    {
      "id": "edge-1766469687215",
      "source": "node-4",
      "sourceHandle": "exec-out",
      "target": "node-7",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1766469688741",
      "source": "node-4",
      "sourceHandle": "response",
      "target": "node-7",
      "targetHandle": "message",
      "animated": false
    }
  ],
  "entryNode": "node-2",
  "created_at": "2025-12-23T06:01:46.129756",
  "updated_at": "2026-01-08T18:36:08.647910"
}