{
  "id": "b16c5a46",
  "name": "basic-react-test",
  "description": "",
  "interfaces": [],
  "nodes": [
    {
      "id": "node-1",
      "type": "on_flow_start",
      "position": {
        "x": -832.0,
        "y": 16.0
      },
      "data": {
        "nodeType": "on_flow_start",
        "label": "On Flow Start",
        "icon": "&#x1F3C1;",
        "headerColor": "#C0392B",
        "inputs": [],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          }
        ]
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-2",
      "type": "agent",
      "position": {
        "x": -544.0,
        "y": 16.0
      },
      "data": {
        "nodeType": "agent",
        "label": "Agent",
        "icon": "&#x1F916;",
        "headerColor": "#4488FF",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          },
          {
            "id": "include_context",
            "label": "use_context",
            "type": "boolean",
            "description": "When true, include this run's active context messages (context.messages) as agent history. If the pin is not connected, the node checkbox is used. Default: false."
          },
          {
            "id": "provider",
            "label": "provider",
            "type": "provider",
            "description": "LLM provider id (e.g. LMStudio). If unset, uses the node’s configured provider."
          },
          {
            "id": "model",
            "label": "model",
            "type": "model",
            "description": "LLM model id/name. If unset, uses the node’s configured model."
          },
          {
            "id": "temperature",
            "label": "temperature",
            "type": "number",
            "description": "Sampling temperature (0 = deterministic). If unset, uses the node’s configured temperature."
          },
          {
            "id": "seed",
            "label": "seed",
            "type": "number",
            "description": "Seed for deterministic sampling (-1 = random/unset). If unset, uses the node’s configured seed."
          },
          {
            "id": "max_iterations",
            "label": "max_iterations",
            "type": "number",
            "description": "Maximum internal ReAct iterations (safety cap). Higher values allow more tool-use steps."
          },
          {
            "id": "max_input_tokens",
            "label": "max_input_tokens",
            "type": "number",
            "description": "Optional per-agent input token budget (max_input_tokens). When set, overrides the run's default _limits.max_input_tokens for the agent sub-run."
          },
          {
            "id": "system",
            "label": "system",
            "type": "string",
            "description": "Optional system prompt for this agent instance (high priority instructions)."
          },
          {
            "id": "task",
            "label": "prompt",
            "type": "string",
            "description": "The task/user prompt for the agent to solve."
          },
          {
            "id": "tools",
            "label": "tools",
            "type": "tools",
            "description": "Allowlist of tool names this agent can call (defense-in-depth; runtime still enforces allowlists)."
          },
          {
            "id": "response_schema",
            "label": "structured_output",
            "type": "object",
            "description": "Optional JSON Schema object (type=object) the final answer must conform to."
          },
          {
            "id": "context",
            "label": "context",
            "type": "object",
            "description": "Optional explicit context object for the agent (e.g. {messages:[...]}). If provided, it can override inherited run context."
          }
        ],
        "outputs": [
          {
            "id": "exec-out",
            "label": "",
            "type": "execution"
          },
          {
            "id": "result",
            "label": "result",
            "type": "object",
            "description": "Structured final agent result (answer + metadata/tool calls depending on agent)."
          },
          {
            "id": "tool_calls",
            "label": "tool_calls",
            "type": "array",
            "description": "Best-effort list of tool call requests extracted from the agent scratchpad trace (post-run). For real-time tool observability, subscribe to the ledger/node_traces stream."
          },
          {
            "id": "tool_results",
            "label": "tool_results",
            "type": "array",
            "description": "Best-effort list of tool results extracted from the agent scratchpad trace (post-run). For real-time tool observability, subscribe to the ledger/node_traces stream."
          },
          {
            "id": "scratchpad",
            "label": "scratchpad",
            "type": "object",
            "description": "Runtime-owned execution trace/scratchpad for observability (LLM/tool steps, timings)."
          }
        ],
        "pinDefaults": {
          "task": "create a SOTA python clone of the game r-type. all the assets, visuals and audio must be generated procedurally. there must be waves of ennemies, the usual power ups for r-type and visual effects. reproduce the same game mechanics and remember the game scroll horizontally with the starship traveling towards the right end of the screen\n"
        },
        "agentConfig": {
          "tools": [
            "list_files",
            "edit_file",
            "analyze_code",
            "read_file",
            "search_files",
            "write_file",
            "execute_command"
          ],
          "provider": "lmstudio",
          "model": "openai/gpt-oss-20b"
        }
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    },
    {
      "id": "node-3",
      "type": "on_flow_end",
      "position": {
        "x": -112.0,
        "y": 16.0
      },
      "data": {
        "nodeType": "on_flow_end",
        "label": "On Flow End",
        "icon": "&#x23F9;",
        "headerColor": "#C0392B",
        "inputs": [
          {
            "id": "exec-in",
            "label": "",
            "type": "execution"
          }
        ],
        "outputs": []
      },
      "label": null,
      "icon": null,
      "headerColor": null,
      "inputs": [],
      "outputs": []
    }
  ],
  "edges": [
    {
      "id": "edge-1768297643833",
      "source": "node-1",
      "sourceHandle": "exec-out",
      "target": "node-2",
      "targetHandle": "exec-in",
      "animated": true
    },
    {
      "id": "edge-1768297652890",
      "source": "node-2",
      "sourceHandle": "exec-out",
      "target": "node-3",
      "targetHandle": "exec-in",
      "animated": true
    }
  ],
  "entryNode": "node-1",
  "created_at": "2026-01-13T09:48:44.941991",
  "updated_at": "2026-01-14T02:08:09.686292"
}